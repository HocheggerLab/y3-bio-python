{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧬 DNA Analysis Toolkit\n",
    "\n",
    "## Real Python Tools for Sequence Analysis\n",
    "\n",
    "Welcome to your **DNA analysis practice toolkit**! These tools demonstrate how to analyze real biological sequences using the fundamental concepts from Lecture 2.\n",
    "\n",
    "**What you'll build:**\n",
    "- 📊 Basic sequence statistics calculator\n",
    "- 🔤 Nucleotide composition analyzer\n",
    "- 🧬 Codon classifier and translator\n",
    "- ✂️ Restriction site finder\n",
    "- ✅ Sequence quality control tool\n",
    "- 🔬 Species comparison analyzer\n",
    "\n",
    "**Skills used:** String manipulation, conditionals, dictionaries - everything from Lecture 2!\n",
    "\n",
    "**Real data:** We'll work with actual ATR gene sequences from human and mouse (from Zenodo scientific repository)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📥 Loading Real Biological Data\n",
    "\n",
    "First, let's download our real gene sequences - the ATR gene from human and mouse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔽 Downloading ATR gene sequences...\n",
      "✓ Human ATR downloaded\n",
      "✓ Mouse ATR downloaded\n",
      "\n",
      "✓ Loaded human ATR: 8,239 bp\n",
      "✓ Loaded mouse ATR: 8,034 bp\n",
      "\n",
      "Ready for analysis! 🧬\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# URLs for ATR gene sequences from Zenodo\n",
    "human_atr_url = \"https://zenodo.org/records/17223635/files/atr_human.fasta?download=1\"\n",
    "mouse_atr_url = \"https://zenodo.org/records/17223635/files/atr_mouse.fasta?download=1\"\n",
    "\n",
    "print(\"🔽 Downloading ATR gene sequences...\")\n",
    "\n",
    "# Download files\n",
    "urllib.request.urlretrieve(human_atr_url, 'atr_human.fasta')\n",
    "print(\"✓ Human ATR downloaded\")\n",
    "\n",
    "urllib.request.urlretrieve(mouse_atr_url, 'atr_mouse.fasta')\n",
    "print(\"✓ Mouse ATR downloaded\")\n",
    "\n",
    "# Simple function to read FASTA sequence\n",
    "def read_fasta_sequence(filename):\n",
    "    \"\"\"Read a simple FASTA file and return the sequence\"\"\"\n",
    "    sequence = \"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line.startswith('>'):  # Skip header lines\n",
    "                sequence += line.upper()\n",
    "    return sequence\n",
    "\n",
    "# Load sequences\n",
    "human_atr = read_fasta_sequence('atr_human.fasta')\n",
    "mouse_atr = read_fasta_sequence('atr_mouse.fasta')\n",
    "\n",
    "print(f\"\\n✓ Loaded human ATR: {len(human_atr):,} bp\")\n",
    "print(f\"✓ Loaded mouse ATR: {len(mouse_atr):,} bp\")\n",
    "print(\"\\nReady for analysis! 🧬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Tool 1: Basic Sequence Statistics\n",
    "\n",
    "**The Problem:** You've received a DNA sequence and need to know its basic properties.\n",
    "\n",
    "**Skills:** String manipulation (`.upper()`, `.count()`, `len()`), basic calculations\n",
    "\n",
    "**Difficulty:** ⭐ Beginner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 SEQUENCE STATISTICS\n",
      "==================================================\n",
      "Sequence: Human ATR (first 1kb)\n",
      "Length: 1,000 bp\n",
      "\n",
      "Nucleotide Composition:\n",
      "  Adenine (A):   283 ( 28.3%)\n",
      "  Thymine (T):   305 ( 30.5%)\n",
      "  Guanine (G):   215 ( 21.5%)\n",
      "  Cytosine (C):  197 ( 19.7%)\n",
      "\n",
      "GC Content: 41.2%\n",
      "AT Content: 58.8%\n",
      "Estimated Tm (simplified): ~2824°C\n",
      "\n",
      "First 60 bases:\n",
      "  GCGCTCTTCCGGCAGCGGTACGTTTGGAGACGCCGGGAACCCGCGTTGGCGTGGTTGACT\n",
      "Last 60 bases:\n",
      "  TTGAAACTCTATGAAGAGCCATTATCAAAGCTGATAAAGACACTATTTCCCTTTGAAGCA\n"
     ]
    }
   ],
   "source": [
    "# Basic Sequence Statistics Calculator\n",
    "# ====================================\n",
    "\n",
    "# Let's analyze the first 1000 bases of human ATR\n",
    "sequence = human_atr[:1000]\n",
    "sequence_name = \"Human ATR (first 1kb)\"\n",
    "\n",
    "# Clean and standardize the sequence\n",
    "clean_sequence = sequence.upper().replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "# Calculate basic statistics\n",
    "length = len(clean_sequence)\n",
    "a_count = clean_sequence.count('A')\n",
    "t_count = clean_sequence.count('T')\n",
    "g_count = clean_sequence.count('G')\n",
    "c_count = clean_sequence.count('C')\n",
    "n_count = clean_sequence.count('N')  # Unknown bases\n",
    "\n",
    "# Calculate GC content (important metric in genomics)\n",
    "gc_content = ((g_count + c_count) / length) * 100 if length > 0 else 0\n",
    "at_content = ((a_count + t_count) / length) * 100 if length > 0 else 0\n",
    "\n",
    "# Calculate melting temperature (simplified formula)\n",
    "# Tm = 4(G+C) + 2(A+T) - simple approximation for short sequences\n",
    "tm_estimate = 4 * (g_count + c_count) + 2 * (a_count + t_count)\n",
    "\n",
    "# Display results\n",
    "print(\"📊 SEQUENCE STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Sequence: {sequence_name}\")\n",
    "print(f\"Length: {length:,} bp\")\n",
    "print()\n",
    "print(\"Nucleotide Composition:\")\n",
    "print(f\"  Adenine (A):  {a_count:4d} ({(a_count/length*100):5.1f}%)\")\n",
    "print(f\"  Thymine (T):  {t_count:4d} ({(t_count/length*100):5.1f}%)\")\n",
    "print(f\"  Guanine (G):  {g_count:4d} ({(g_count/length*100):5.1f}%)\")\n",
    "print(f\"  Cytosine (C): {c_count:4d} ({(c_count/length*100):5.1f}%)\")\n",
    "if n_count > 0:\n",
    "    print(f\"  Unknown (N):  {n_count:4d} ({(n_count/length*100):5.1f}%)\")\n",
    "print()\n",
    "print(f\"GC Content: {gc_content:.1f}%\")\n",
    "print(f\"AT Content: {at_content:.1f}%\")\n",
    "print(f\"Estimated Tm (simplified): ~{tm_estimate}°C\")\n",
    "print()\n",
    "print(f\"First 60 bases:\")\n",
    "print(f\"  {clean_sequence[:60]}\")\n",
    "print(f\"Last 60 bases:\")\n",
    "print(f\"  {clean_sequence[-60:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Try It Yourself!\n",
    "\n",
    "**Exercise:** Analyze the first 1000 bases of mouse ATR. How does it compare to human?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - analyze mouse_atr[:1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔤 Tool 2: Nucleotide Composition Analyzer\n",
    "\n",
    "**The Problem:** You need to count nucleotides and store results in an organized way.\n",
    "\n",
    "**Skills:** Dictionaries for data storage, loops for processing\n",
    "\n",
    "**Difficulty:** ⭐⭐ Beginner-Intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔤 NUCLEOTIDE COMPOSITION ANALYSIS\n",
      "==================================================\n",
      "\n",
      "Human ATR (first 5kb)\n",
      "  Length: 5,000 bp\n",
      "  Composition:\n",
      "    A:  1502 (30.04%)\n",
      "    T:  1509 (30.18%)\n",
      "    G:  1037 (20.74%)\n",
      "    C:   952 (19.04%)\n",
      "  GC Content: 39.78%\n",
      "  Purine (A+G): 50.78%\n",
      "  Pyrimidine (C+T): 49.22%\n",
      "\n",
      "Mouse ATR (first 5kb)\n",
      "  Length: 5,000 bp\n",
      "  Composition:\n",
      "    A:  1476 (29.52%)\n",
      "    T:  1493 (29.86%)\n",
      "    G:  1064 (21.28%)\n",
      "    C:   967 (19.34%)\n",
      "  GC Content: 40.62%\n",
      "  Purine (A+G): 50.80%\n",
      "  Pyrimidine (C+T): 49.20%\n",
      "\n",
      "📊 Comparison:\n",
      "  GC content difference: 0.84%\n",
      "  → Very similar GC content between species\n"
     ]
    }
   ],
   "source": [
    "# Nucleotide Composition Analyzer\n",
    "# ===============================\n",
    "\n",
    "def analyze_nucleotide_composition(sequence, sequence_name=\"Unknown\"):\n",
    "    \"\"\"Analyze and display nucleotide composition using dictionaries\"\"\"\n",
    "    \n",
    "    # Clean sequence\n",
    "    clean_seq = sequence.upper().strip()\n",
    "    \n",
    "    # Initialize composition dictionary\n",
    "    composition = {\n",
    "        'A': 0,\n",
    "        'T': 0,\n",
    "        'G': 0,\n",
    "        'C': 0,\n",
    "        'N': 0\n",
    "    }\n",
    "    \n",
    "    # Count nucleotides\n",
    "    for base in clean_seq:\n",
    "        if base in composition:\n",
    "            composition[base] += 1\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    total_bases = len(clean_seq)\n",
    "    valid_bases = total_bases - composition['N']\n",
    "    \n",
    "    # Store results in a comprehensive dictionary\n",
    "    results = {\n",
    "        'name': sequence_name,\n",
    "        'length': total_bases,\n",
    "        'composition': composition,\n",
    "        'gc_content': ((composition['G'] + composition['C']) / valid_bases * 100) if valid_bases > 0 else 0,\n",
    "        'purine_content': ((composition['A'] + composition['G']) / valid_bases * 100) if valid_bases > 0 else 0,\n",
    "        'pyrimidine_content': ((composition['C'] + composition['T']) / valid_bases * 100) if valid_bases > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyze both species\n",
    "human_results = analyze_nucleotide_composition(human_atr[:5000], \"Human ATR (first 5kb)\")\n",
    "mouse_results = analyze_nucleotide_composition(mouse_atr[:5000], \"Mouse ATR (first 5kb)\")\n",
    "\n",
    "# Display results\n",
    "print(\"🔤 NUCLEOTIDE COMPOSITION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for results in [human_results, mouse_results]:\n",
    "    print(f\"\\n{results['name']}\")\n",
    "    print(f\"  Length: {results['length']:,} bp\")\n",
    "    print(f\"  Composition:\")\n",
    "    for base, count in results['composition'].items():\n",
    "        if count > 0:\n",
    "            percent = (count / results['length']) * 100\n",
    "            print(f\"    {base}: {count:5d} ({percent:5.2f}%)\")\n",
    "    print(f\"  GC Content: {results['gc_content']:.2f}%\")\n",
    "    print(f\"  Purine (A+G): {results['purine_content']:.2f}%\")\n",
    "    print(f\"  Pyrimidine (C+T): {results['pyrimidine_content']:.2f}%\")\n",
    "\n",
    "# Compare the two\n",
    "print(\"\\n📊 Comparison:\")\n",
    "gc_diff = abs(human_results['gc_content'] - mouse_results['gc_content'])\n",
    "print(f\"  GC content difference: {gc_diff:.2f}%\")\n",
    "if gc_diff < 2:\n",
    "    print(\"  → Very similar GC content between species\")\n",
    "elif gc_diff < 5:\n",
    "    print(\"  → Moderately similar GC content\")\n",
    "else:\n",
    "    print(\"  → Notable difference in GC content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧬 Tool 3: Codon Classifier and Translator\n",
    "\n",
    "**The Problem:** You need to identify special codons (start, stop) and translate sequences.\n",
    "\n",
    "**Skills:** Dictionaries for codon tables, conditionals for classification\n",
    "\n",
    "**Difficulty:** ⭐⭐ Intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧬 CODON ANALYSIS\n",
      "==================================================\n",
      "Sequence: GCGCTCTTCCGGCAGCGGTACGTTTGGAGA\n",
      "\n",
      "Codon-by-codon analysis:\n",
      "  Position  0: GCG → A [SENSE  ] Coding\n",
      "  Position  3: CTC → L [SENSE  ] Coding\n",
      "  Position  6: TTC → F [SENSE  ] Coding\n",
      "  Position  9: CGG → R [SENSE  ] Coding\n",
      "  Position 12: CAG → Q [SENSE  ] Coding\n",
      "  Position 15: CGG → R [SENSE  ] Coding\n",
      "  Position 18: TAC → Y [SENSE  ] Coding\n",
      "  Position 21: GTT → V [SENSE  ] Coding\n",
      "  Position 24: TGG → W [SENSE  ] Coding\n",
      "  Position 27: AGA → R [SENSE  ] Coding\n",
      "\n",
      "📝 TRANSLATION EXAMPLE\n",
      "==================================================\n",
      "DNA (300 bp):\n",
      "  GCGCTCTTCCGGCAGCGGTACGTTTGGAGACGCCGGGAACCCGCGTTGGCGTGGTTGACT\n",
      "  AGTGCCTCGCAGCCTCAGCATGGGGGAACATGGCCTGGAGCTGGCTTCCATGATCCCCGC\n",
      "  CCTGCGGGAGCTGGGCAGTGCCACACCAGAGGAATATAATACAGTTGTACAGAAGCCAAG\n",
      "  ACAAATTCTGTGTCAATTCATTGACCGGATACTTACAGATGTAAATGTTGTTGCTGTAGA\n",
      "  ACTTGTAAAGAAAACTGACTCTCAGCCAACCTCCGTGATGTTGCTTGATTTCATCCAGCA\n",
      "\n",
      "Protein (53 amino acids):\n",
      "  ALFRQRYVWRRREPALAWLTSASQPQHGGTWPGAGFHDPRPAGAGQCHTRGI*\n",
      "\n",
      "🔍 CODON FREQUENCY (first 3kb)\n",
      "==================================================\n",
      "Total codons analyzed: 1000\n",
      "  Start codons (ATG): 8\n",
      "  Stop codons: 80\n",
      "  Sense codons: 912\n"
     ]
    }
   ],
   "source": [
    "# Codon Classifier and Translator\n",
    "# ===============================\n",
    "\n",
    "# Genetic code dictionary (simplified - showing key codons)\n",
    "genetic_code = {\n",
    "    # Start codon\n",
    "    'ATG': 'M',  # Methionine (Start)\n",
    "    # Stop codons\n",
    "    'TAA': '*',  # Stop (Ochre)\n",
    "    'TAG': '*',  # Stop (Amber)\n",
    "    'TGA': '*',  # Stop (Opal)\n",
    "    # Common amino acids\n",
    "    'GCT': 'A', 'GCC': 'A', 'GCA': 'A', 'GCG': 'A',  # Alanine\n",
    "    'TGT': 'C', 'TGC': 'C',  # Cysteine\n",
    "    'GAT': 'D', 'GAC': 'D',  # Aspartic acid\n",
    "    'GAA': 'E', 'GAG': 'E',  # Glutamic acid\n",
    "    'TTT': 'F', 'TTC': 'F',  # Phenylalanine\n",
    "    'GGT': 'G', 'GGC': 'G', 'GGA': 'G', 'GGG': 'G',  # Glycine\n",
    "    'CAT': 'H', 'CAC': 'H',  # Histidine\n",
    "    'ATT': 'I', 'ATC': 'I', 'ATA': 'I',  # Isoleucine\n",
    "    'AAA': 'K', 'AAG': 'K',  # Lysine\n",
    "    'TTA': 'L', 'TTG': 'L', 'CTT': 'L', 'CTC': 'L', 'CTA': 'L', 'CTG': 'L',  # Leucine\n",
    "    'AAT': 'N', 'AAC': 'N',  # Asparagine\n",
    "    'CCT': 'P', 'CCC': 'P', 'CCA': 'P', 'CCG': 'P',  # Proline\n",
    "    'CAA': 'Q', 'CAG': 'Q',  # Glutamine\n",
    "    'CGT': 'R', 'CGC': 'R', 'CGA': 'R', 'CGG': 'R', 'AGA': 'R', 'AGG': 'R',  # Arginine\n",
    "    'TCT': 'S', 'TCC': 'S', 'TCA': 'S', 'TCG': 'S', 'AGT': 'S', 'AGC': 'S',  # Serine\n",
    "    'ACT': 'T', 'ACC': 'T', 'ACA': 'T', 'ACG': 'T',  # Threonine\n",
    "    'GTT': 'V', 'GTC': 'V', 'GTA': 'V', 'GTG': 'V',  # Valine\n",
    "    'TGG': 'W',  # Tryptophan\n",
    "    'TAT': 'Y', 'TAC': 'Y',  # Tyrosine\n",
    "}\n",
    "\n",
    "def classify_codon(codon):\n",
    "    \"\"\"Classify a codon as start, stop, or sense\"\"\"\n",
    "    codon = codon.upper()\n",
    "    \n",
    "    if codon == 'ATG':\n",
    "        return 'START', 'M', 'Methionine'\n",
    "    elif codon in ['TAA', 'TAG', 'TGA']:\n",
    "        stop_names = {'TAA': 'Ochre', 'TAG': 'Amber', 'TGA': 'Opal'}\n",
    "        return 'STOP', '*', stop_names[codon]\n",
    "    elif codon in genetic_code:\n",
    "        return 'SENSE', genetic_code[codon], 'Coding'\n",
    "    else:\n",
    "        return 'UNKNOWN', '?', 'Not in codon table'\n",
    "\n",
    "def translate_sequence(dna_sequence, start_pos=0):\n",
    "    \"\"\"Translate DNA to protein sequence\"\"\"\n",
    "    dna = dna_sequence[start_pos:].upper()\n",
    "    protein = \"\"\n",
    "    \n",
    "    # Process codons (groups of 3)\n",
    "    for i in range(0, len(dna) - 2, 3):\n",
    "        codon = dna[i:i+3]\n",
    "        \n",
    "        # Get amino acid from codon table\n",
    "        amino_acid = genetic_code.get(codon, 'X')  # X for unknown\n",
    "        protein += amino_acid\n",
    "        \n",
    "        # Stop at stop codon\n",
    "        if amino_acid == '*':\n",
    "            break\n",
    "    \n",
    "    return protein\n",
    "\n",
    "# Analyze first few codons of ATR gene\n",
    "print(\"🧬 CODON ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get first 30 bases (10 codons)\n",
    "test_sequence = human_atr[:30]\n",
    "print(f\"Sequence: {test_sequence}\\n\")\n",
    "\n",
    "print(\"Codon-by-codon analysis:\")\n",
    "for i in range(0, 30, 3):\n",
    "    codon = test_sequence[i:i+3]\n",
    "    codon_type, amino_acid, description = classify_codon(codon)\n",
    "    print(f\"  Position {i:2d}: {codon} → {amino_acid} [{codon_type:7s}] {description}\")\n",
    "\n",
    "# Translate longer sequence\n",
    "print(\"\\n📝 TRANSLATION EXAMPLE\")\n",
    "print(\"=\" * 50)\n",
    "segment = human_atr[:300]  # First 300 bases\n",
    "protein = translate_sequence(segment)\n",
    "\n",
    "print(f\"DNA ({len(segment)} bp):\")\n",
    "# Print in groups of 60\n",
    "for i in range(0, len(segment), 60):\n",
    "    print(f\"  {segment[i:i+60]}\")\n",
    "\n",
    "print(f\"\\nProtein ({len(protein)} amino acids):\")\n",
    "# Print in groups of 60\n",
    "for i in range(0, len(protein), 60):\n",
    "    print(f\"  {protein[i:i+60]}\")\n",
    "\n",
    "# Count special codons in first 3000 bases\n",
    "print(\"\\n🔍 CODON FREQUENCY (first 3kb)\")\n",
    "print(\"=\" * 50)\n",
    "analysis_region = human_atr[:3000]\n",
    "\n",
    "start_count = 0\n",
    "stop_count = 0\n",
    "sense_count = 0\n",
    "\n",
    "for i in range(0, len(analysis_region) - 2, 3):\n",
    "    codon = analysis_region[i:i+3]\n",
    "    codon_type, _, _ = classify_codon(codon)\n",
    "    \n",
    "    if codon_type == 'START':\n",
    "        start_count += 1\n",
    "    elif codon_type == 'STOP':\n",
    "        stop_count += 1\n",
    "    elif codon_type == 'SENSE':\n",
    "        sense_count += 1\n",
    "\n",
    "total_codons = (len(analysis_region) // 3)\n",
    "print(f\"Total codons analyzed: {total_codons}\")\n",
    "print(f\"  Start codons (ATG): {start_count}\")\n",
    "print(f\"  Stop codons: {stop_count}\")\n",
    "print(f\"  Sense codons: {sense_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✂️ Tool 4: Restriction Site Finder\n",
    "\n",
    "**The Problem:** You need to find where restriction enzymes will cut your sequence.\n",
    "\n",
    "**Skills:** String searching, conditionals, loops, dictionaries for enzyme data\n",
    "\n",
    "**Difficulty:** ⭐⭐⭐ Intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✂️ RESTRICTION SITE ANALYSIS\n",
      "==================================================\n",
      "Sequence: Human ATR (first 10,000 bp)\n",
      "\n",
      "Restriction sites found: 4 different enzymes\n",
      "\n",
      "HindIII:\n",
      "  Recognition site: AAGCTT (A^AGCTT)\n",
      "  Number of sites: 6\n",
      "  First 5 positions: [1001, 2354, 3993, 4248, 5589]...\n",
      "\n",
      "PstI:\n",
      "  Recognition site: CTGCAG (CTGCA^G)\n",
      "  Number of sites: 6\n",
      "  First 5 positions: [1126, 2056, 3101, 3767, 5851]...\n",
      "\n",
      "EcoRI:\n",
      "  Recognition site: GAATTC (G^AATTC)\n",
      "  Number of sites: 4\n",
      "  Positions: [370, 2124, 5751, 7096]\n",
      "\n",
      "XbaI:\n",
      "  Recognition site: TCTAGA (T^CTAGA)\n",
      "  Number of sites: 2\n",
      "  Positions: [4974, 6744]\n",
      "\n",
      "💡 CLONING RECOMMENDATIONS\n",
      "==================================================\n",
      "No unique cutters found in this region.\n",
      "\n",
      "Suggested enzyme pairs for directional cloning:\n",
      "  EcoRI + HindIII: 4 and 6 sites\n",
      "  EcoRI + PstI: 4 and 6 sites\n",
      "  HindIII + PstI: 6 and 6 sites\n"
     ]
    }
   ],
   "source": [
    "# Restriction Site Finder\n",
    "# ======================\n",
    "\n",
    "# Common restriction enzymes dictionary\n",
    "restriction_enzymes = {\n",
    "    'EcoRI': {'sequence': 'GAATTC', 'cut_pos': 1, 'description': 'G^AATTC'},\n",
    "    'BamHI': {'sequence': 'GGATCC', 'cut_pos': 1, 'description': 'G^GATCC'},\n",
    "    'HindIII': {'sequence': 'AAGCTT', 'cut_pos': 1, 'description': 'A^AGCTT'},\n",
    "    'PstI': {'sequence': 'CTGCAG', 'cut_pos': 5, 'description': 'CTGCA^G'},\n",
    "    'SmaI': {'sequence': 'CCCGGG', 'cut_pos': 3, 'description': 'CCC^GGG'},\n",
    "    'XbaI': {'sequence': 'TCTAGA', 'cut_pos': 1, 'description': 'T^CTAGA'},\n",
    "    'NotI': {'sequence': 'GCGGCCGC', 'cut_pos': 2, 'description': 'GC^GGCCGC'},\n",
    "}\n",
    "\n",
    "def find_restriction_sites(sequence, enzyme_name, enzyme_data):\n",
    "    \"\"\"Find all positions of a restriction site in a sequence\"\"\"\n",
    "    recognition_site = enzyme_data['sequence']\n",
    "    positions = []\n",
    "    \n",
    "    # Search for all occurrences\n",
    "    start = 0\n",
    "    while True:\n",
    "        pos = sequence.find(recognition_site, start)\n",
    "        if pos == -1:  # No more found\n",
    "            break\n",
    "        positions.append(pos)\n",
    "        start = pos + 1  # Continue searching after this position\n",
    "    \n",
    "    return positions\n",
    "\n",
    "def analyze_restriction_sites(sequence, sequence_name=\"Unknown\"):\n",
    "    \"\"\"Analyze sequence for all restriction sites\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for enzyme_name, enzyme_data in restriction_enzymes.items():\n",
    "        positions = find_restriction_sites(sequence, enzyme_name, enzyme_data)\n",
    "        \n",
    "        if positions:  # Only store if sites found\n",
    "            results[enzyme_name] = {\n",
    "                'positions': positions,\n",
    "                'count': len(positions),\n",
    "                'recognition_site': enzyme_data['sequence'],\n",
    "                'description': enzyme_data['description']\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyze first 10kb of human ATR\n",
    "print(\"✂️ RESTRICTION SITE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "analysis_sequence = human_atr[:10000]\n",
    "sites = analyze_restriction_sites(analysis_sequence, \"Human ATR (first 10kb)\")\n",
    "\n",
    "print(f\"Sequence: Human ATR (first 10,000 bp)\")\n",
    "print(f\"\\nRestriction sites found: {len(sites)} different enzymes\\n\")\n",
    "\n",
    "if sites:\n",
    "    # Sort by number of sites (most common first)\n",
    "    sorted_enzymes = sorted(sites.items(), key=lambda x: x[1]['count'], reverse=True)\n",
    "    \n",
    "    for enzyme_name, data in sorted_enzymes:\n",
    "        print(f\"{enzyme_name}:\")\n",
    "        print(f\"  Recognition site: {data['recognition_site']} ({data['description']})\")\n",
    "        print(f\"  Number of sites: {data['count']}\")\n",
    "        \n",
    "        # Show first 5 positions\n",
    "        if data['count'] <= 5:\n",
    "            print(f\"  Positions: {data['positions']}\")\n",
    "        else:\n",
    "            print(f\"  First 5 positions: {data['positions'][:5]}...\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No restriction sites found in this region.\")\n",
    "\n",
    "# Practical recommendation\n",
    "print(\"💡 CLONING RECOMMENDATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if sites:\n",
    "    # Find enzymes with exactly 1 site (best for cloning)\n",
    "    unique_cutters = [name for name, data in sites.items() if data['count'] == 1]\n",
    "    \n",
    "    if unique_cutters:\n",
    "        print(f\"Unique cutters (1 site - ideal for cloning):\")\n",
    "        for enzyme in unique_cutters:\n",
    "            pos = sites[enzyme]['positions'][0]\n",
    "            print(f\"  {enzyme}: cuts at position {pos}\")\n",
    "    else:\n",
    "        print(\"No unique cutters found in this region.\")\n",
    "    \n",
    "    # Find enzyme pairs for directional cloning\n",
    "    print(\"\\nSuggested enzyme pairs for directional cloning:\")\n",
    "    enzyme_list = list(sites.keys())\n",
    "    if len(enzyme_list) >= 2:\n",
    "        for i in range(min(3, len(enzyme_list))):\n",
    "            for j in range(i+1, min(3, len(enzyme_list))):\n",
    "                e1, e2 = enzyme_list[i], enzyme_list[j]\n",
    "                print(f\"  {e1} + {e2}: {sites[e1]['count']} and {sites[e2]['count']} sites\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Tool 5: Sequence Quality Analyzer\n",
    "\n",
    "**The Problem:** You need to validate sequences meet quality standards for analysis.\n",
    "\n",
    "**Skills:** Conditionals for validation, dictionaries for results, comprehensive logic\n",
    "\n",
    "**Difficulty:** ⭐⭐⭐ Intermediate-Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SEQUENCE QUALITY CONTROL\n",
      "==================================================\n",
      "\n",
      "Human ATR (5kb)\n",
      "--------------------------------------------------\n",
      "✅ PASSED - Sequence meets quality standards\n",
      "\n",
      "Metrics:\n",
      "  length: 5,000\n",
      "  n_percent: 0.00\n",
      "  gc_content: 39.78\n",
      "  max_homopolymer: 10\n",
      "\n",
      "⚠️  Warnings:\n",
      "  • GC content near boundary: 39.8%\n",
      "\n",
      "Mouse ATR (5kb)\n",
      "--------------------------------------------------\n",
      "✅ PASSED - Sequence meets quality standards\n",
      "\n",
      "Metrics:\n",
      "  length: 5,000\n",
      "  n_percent: 0.00\n",
      "  gc_content: 40.62\n",
      "  max_homopolymer: 6\n"
     ]
    }
   ],
   "source": [
    "# Sequence Quality Analyzer\n",
    "# =========================\n",
    "\n",
    "def quality_control_sequence(sequence, sequence_name=\"Unknown\", \n",
    "                            min_length=100, max_n_percent=5, \n",
    "                            gc_range=(30, 70)):\n",
    "    \"\"\"\n",
    "    Perform comprehensive quality control on a DNA sequence\n",
    "    \n",
    "    Parameters:\n",
    "    - sequence: DNA sequence to analyze\n",
    "    - sequence_name: identifier for the sequence\n",
    "    - min_length: minimum acceptable length\n",
    "    - max_n_percent: maximum percentage of unknown bases\n",
    "    - gc_range: tuple of (min_gc, max_gc) percentages\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with QC results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize results\n",
    "    qc_results = {\n",
    "        'name': sequence_name,\n",
    "        'passed': True,\n",
    "        'warnings': [],\n",
    "        'errors': [],\n",
    "        'metrics': {}\n",
    "    }\n",
    "    \n",
    "    # Clean sequence\n",
    "    clean_seq = sequence.upper().strip()\n",
    "    \n",
    "    # Check 1: Length\n",
    "    seq_length = len(clean_seq)\n",
    "    qc_results['metrics']['length'] = seq_length\n",
    "    \n",
    "    if seq_length < min_length:\n",
    "        qc_results['errors'].append(f\"Sequence too short: {seq_length} bp < {min_length} bp\")\n",
    "        qc_results['passed'] = False\n",
    "    elif seq_length < min_length * 2:\n",
    "        qc_results['warnings'].append(f\"Sequence is short: {seq_length} bp\")\n",
    "    \n",
    "    # Check 2: Unknown bases (N)\n",
    "    n_count = clean_seq.count('N')\n",
    "    n_percent = (n_count / seq_length * 100) if seq_length > 0 else 0\n",
    "    qc_results['metrics']['n_percent'] = n_percent\n",
    "    \n",
    "    if n_percent > max_n_percent:\n",
    "        qc_results['errors'].append(f\"Too many unknown bases: {n_percent:.1f}% > {max_n_percent}%\")\n",
    "        qc_results['passed'] = False\n",
    "    elif n_percent > max_n_percent / 2:\n",
    "        qc_results['warnings'].append(f\"Moderate unknown bases: {n_percent:.1f}%\")\n",
    "    \n",
    "    # Check 3: GC content\n",
    "    g_count = clean_seq.count('G')\n",
    "    c_count = clean_seq.count('C')\n",
    "    valid_bases = seq_length - n_count\n",
    "    \n",
    "    if valid_bases > 0:\n",
    "        gc_percent = ((g_count + c_count) / valid_bases) * 100\n",
    "        qc_results['metrics']['gc_content'] = gc_percent\n",
    "        \n",
    "        if gc_percent < gc_range[0] or gc_percent > gc_range[1]:\n",
    "            qc_results['errors'].append(\n",
    "                f\"GC content out of range: {gc_percent:.1f}% not in {gc_range[0]}-{gc_range[1]}%\"\n",
    "            )\n",
    "            qc_results['passed'] = False\n",
    "        elif gc_percent < gc_range[0] + 5 or gc_percent > gc_range[1] - 5:\n",
    "            qc_results['warnings'].append(\n",
    "                f\"GC content near boundary: {gc_percent:.1f}%\"\n",
    "            )\n",
    "    \n",
    "    # Check 4: Invalid characters\n",
    "    valid_bases = set('ATCGN')\n",
    "    invalid_chars = set(clean_seq) - valid_bases\n",
    "    \n",
    "    if invalid_chars:\n",
    "        qc_results['errors'].append(\n",
    "            f\"Invalid characters found: {sorted(invalid_chars)}\"\n",
    "        )\n",
    "        qc_results['passed'] = False\n",
    "    \n",
    "    # Check 5: Complexity (look for low complexity regions)\n",
    "    # Simple check: look for long stretches of same base\n",
    "    max_repeat = 0\n",
    "    current_repeat = 1\n",
    "    \n",
    "    for i in range(1, len(clean_seq)):\n",
    "        if clean_seq[i] == clean_seq[i-1]:\n",
    "            current_repeat += 1\n",
    "            max_repeat = max(max_repeat, current_repeat)\n",
    "        else:\n",
    "            current_repeat = 1\n",
    "    \n",
    "    qc_results['metrics']['max_homopolymer'] = max_repeat\n",
    "    \n",
    "    if max_repeat > 10:\n",
    "        qc_results['warnings'].append(\n",
    "            f\"Long homopolymer detected: {max_repeat} bp (may indicate low complexity)\"\n",
    "        )\n",
    "    \n",
    "    return qc_results\n",
    "\n",
    "# Test with human and mouse ATR\n",
    "print(\"✅ SEQUENCE QUALITY CONTROL\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze first 5kb of each\n",
    "human_qc = quality_control_sequence(\n",
    "    human_atr[:5000], \n",
    "    \"Human ATR (5kb)\",\n",
    "    min_length=1000,\n",
    "    gc_range=(35, 65)\n",
    ")\n",
    "\n",
    "mouse_qc = quality_control_sequence(\n",
    "    mouse_atr[:5000],\n",
    "    \"Mouse ATR (5kb)\",\n",
    "    min_length=1000,\n",
    "    gc_range=(35, 65)\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for qc in [human_qc, mouse_qc]:\n",
    "    print(f\"\\n{qc['name']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Overall status\n",
    "    if qc['passed']:\n",
    "        print(\"✅ PASSED - Sequence meets quality standards\")\n",
    "    else:\n",
    "        print(\"❌ FAILED - Sequence does not meet quality standards\")\n",
    "    \n",
    "    # Metrics\n",
    "    print(\"\\nMetrics:\")\n",
    "    for metric, value in qc['metrics'].items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {metric}: {value:.2f}\")\n",
    "        else:\n",
    "            print(f\"  {metric}: {value:,}\")\n",
    "    \n",
    "    # Warnings\n",
    "    if qc['warnings']:\n",
    "        print(\"\\n⚠️  Warnings:\")\n",
    "        for warning in qc['warnings']:\n",
    "            print(f\"  • {warning}\")\n",
    "    \n",
    "    # Errors\n",
    "    if qc['errors']:\n",
    "        print(\"\\n❌ Errors:\")\n",
    "        for error in qc['errors']:\n",
    "            print(f\"  • {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔬 Tool 6: Species Comparison Analyzer\n",
    "\n",
    "**The Problem:** You need to compare sequences from different species to understand conservation.\n",
    "\n",
    "**Skills:** All concepts combined - strings, conditionals, dictionaries, loops\n",
    "\n",
    "**Difficulty:** ⭐⭐⭐⭐ Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 SPECIES COMPARISON: Human vs Mouse ATR\n",
      "==================================================\n",
      "\n",
      "📏 LENGTH COMPARISON\n",
      "--------------------------------------------------\n",
      "Human ATR: 8,239 bp\n",
      "Mouse ATR: 8,034 bp\n",
      "Difference: 205 bp\n",
      "Length ratio: 1.026\n",
      "\n",
      "🧬 COMPOSITION COMPARISON\n",
      "--------------------------------------------------\n",
      "Human ATR GC content: 39.69%\n",
      "Mouse ATR GC content: 41.35%\n",
      "GC difference: 1.66%\n",
      "→ Very similar GC content (highly conserved)\n",
      "\n",
      "🎯 SEQUENCE SIMILARITY\n",
      "--------------------------------------------------\n",
      "Compared region: 8,034 bp\n",
      "Identical bases: 2,000\n",
      "Percent identity: 24.89%\n",
      "Conservation level: Low (<70%)\n",
      "\n",
      "🔍 HIGHLY CONSERVED REGIONS (>90% identity)\n",
      "--------------------------------------------------\n",
      "No highly conserved regions found (>90% identity)\n",
      "\n",
      "💡 BIOLOGICAL INTERPRETATION\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Species Comparison Analyzer\n",
    "# ==========================\n",
    "\n",
    "def compare_sequences(seq1, seq2, seq1_name=\"Sequence 1\", seq2_name=\"Sequence 2\", \n",
    "                     window_size=100):\n",
    "    \"\"\"\n",
    "    Comprehensive comparison of two DNA sequences\n",
    "    \n",
    "    Parameters:\n",
    "    - seq1, seq2: sequences to compare\n",
    "    - seq1_name, seq2_name: names for the sequences\n",
    "    - window_size: size of sliding window for local similarity\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with comprehensive comparison results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Clean sequences\n",
    "    s1 = seq1.upper().strip()\n",
    "    s2 = seq2.upper().strip()\n",
    "    \n",
    "    results = {\n",
    "        'seq1_name': seq1_name,\n",
    "        'seq2_name': seq2_name,\n",
    "        'lengths': {},\n",
    "        'composition': {},\n",
    "        'similarity': {},\n",
    "        'conservation_regions': []\n",
    "    }\n",
    "    \n",
    "    # 1. Length comparison\n",
    "    results['lengths'] = {\n",
    "        seq1_name: len(s1),\n",
    "        seq2_name: len(s2),\n",
    "        'difference': abs(len(s1) - len(s2)),\n",
    "        'ratio': len(s1) / len(s2) if len(s2) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    # 2. GC content comparison\n",
    "    def calc_gc(seq):\n",
    "        gc = seq.count('G') + seq.count('C')\n",
    "        return (gc / len(seq) * 100) if len(seq) > 0 else 0\n",
    "    \n",
    "    gc1 = calc_gc(s1)\n",
    "    gc2 = calc_gc(s2)\n",
    "    \n",
    "    results['composition'] = {\n",
    "        f'{seq1_name}_gc': gc1,\n",
    "        f'{seq2_name}_gc': gc2,\n",
    "        'gc_difference': abs(gc1 - gc2)\n",
    "    }\n",
    "    \n",
    "    # 3. Overall similarity (for overlapping region)\n",
    "    overlap_length = min(len(s1), len(s2))\n",
    "    \n",
    "    if overlap_length > 0:\n",
    "        identical_bases = sum(1 for i in range(overlap_length) if s1[i] == s2[i])\n",
    "        similarity_percent = (identical_bases / overlap_length) * 100\n",
    "        \n",
    "        results['similarity'] = {\n",
    "            'overlap_length': overlap_length,\n",
    "            'identical_bases': identical_bases,\n",
    "            'percent_identity': similarity_percent\n",
    "        }\n",
    "    \n",
    "    # 4. Find highly conserved regions (sliding window)\n",
    "    if overlap_length >= window_size:\n",
    "        conserved_regions = []\n",
    "        \n",
    "        for i in range(0, overlap_length - window_size + 1, window_size // 2):\n",
    "            window1 = s1[i:i+window_size]\n",
    "            window2 = s2[i:i+window_size]\n",
    "            \n",
    "            matches = sum(1 for a, b in zip(window1, window2) if a == b)\n",
    "            window_similarity = (matches / window_size) * 100\n",
    "            \n",
    "            # Consider highly conserved if >90% identical\n",
    "            if window_similarity > 90:\n",
    "                conserved_regions.append({\n",
    "                    'start': i,\n",
    "                    'end': i + window_size,\n",
    "                    'similarity': window_similarity\n",
    "                })\n",
    "        \n",
    "        # Merge adjacent conserved regions\n",
    "        if conserved_regions:\n",
    "            merged = [conserved_regions[0]]\n",
    "            for region in conserved_regions[1:]:\n",
    "                if region['start'] <= merged[-1]['end']:\n",
    "                    merged[-1]['end'] = region['end']\n",
    "                    merged[-1]['similarity'] = max(merged[-1]['similarity'], region['similarity'])\n",
    "                else:\n",
    "                    merged.append(region)\n",
    "            \n",
    "            results['conservation_regions'] = merged\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Compare human and mouse ATR\n",
    "print(\"🔬 SPECIES COMPARISON: Human vs Mouse ATR\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Compare first 10kb\n",
    "comparison = compare_sequences(\n",
    "    human_atr[:10000],\n",
    "    mouse_atr[:10000],\n",
    "    \"Human ATR\",\n",
    "    \"Mouse ATR\",\n",
    "    window_size=100\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n📏 LENGTH COMPARISON\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{comparison['seq1_name']}: {comparison['lengths']['Human ATR']:,} bp\")\n",
    "print(f\"{comparison['seq2_name']}: {comparison['lengths']['Mouse ATR']:,} bp\")\n",
    "print(f\"Difference: {comparison['lengths']['difference']:,} bp\")\n",
    "print(f\"Length ratio: {comparison['lengths']['ratio']:.3f}\")\n",
    "\n",
    "print(\"\\n🧬 COMPOSITION COMPARISON\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{comparison['seq1_name']} GC content: {comparison['composition']['Human ATR_gc']:.2f}%\")\n",
    "print(f\"{comparison['seq2_name']} GC content: {comparison['composition']['Mouse ATR_gc']:.2f}%\")\n",
    "print(f\"GC difference: {comparison['composition']['gc_difference']:.2f}%\")\n",
    "\n",
    "if comparison['composition']['gc_difference'] < 2:\n",
    "    print(\"→ Very similar GC content (highly conserved)\")\n",
    "elif comparison['composition']['gc_difference'] < 5:\n",
    "    print(\"→ Similar GC content (well conserved)\")\n",
    "else:\n",
    "    print(\"→ Notable GC difference (less conserved)\")\n",
    "\n",
    "print(\"\\n🎯 SEQUENCE SIMILARITY\")\n",
    "print(\"-\" * 50)\n",
    "if 'similarity' in comparison:\n",
    "    sim = comparison['similarity']\n",
    "    print(f\"Compared region: {sim['overlap_length']:,} bp\")\n",
    "    print(f\"Identical bases: {sim['identical_bases']:,}\")\n",
    "    print(f\"Percent identity: {sim['percent_identity']:.2f}%\")\n",
    "    \n",
    "    # Interpret similarity\n",
    "    if sim['percent_identity'] > 95:\n",
    "        conservation_level = \"Extremely high (>95%)\"\n",
    "    elif sim['percent_identity'] > 85:\n",
    "        conservation_level = \"High (85-95%)\"\n",
    "    elif sim['percent_identity'] > 70:\n",
    "        conservation_level = \"Moderate (70-85%)\"\n",
    "    else:\n",
    "        conservation_level = \"Low (<70%)\"\n",
    "    \n",
    "    print(f\"Conservation level: {conservation_level}\")\n",
    "\n",
    "print(\"\\n🔍 HIGHLY CONSERVED REGIONS (>90% identity)\")\n",
    "print(\"-\" * 50)\n",
    "if comparison['conservation_regions']:\n",
    "    print(f\"Found {len(comparison['conservation_regions'])} highly conserved regions:\\n\")\n",
    "    \n",
    "    for i, region in enumerate(comparison['conservation_regions'][:5], 1):  # Show first 5\n",
    "        length = region['end'] - region['start']\n",
    "        print(f\"  Region {i}:\")\n",
    "        print(f\"    Position: {region['start']:,} - {region['end']:,} bp\")\n",
    "        print(f\"    Length: {length:,} bp\")\n",
    "        print(f\"    Identity: {region['similarity']:.1f}%\")\n",
    "        print()\n",
    "    \n",
    "    if len(comparison['conservation_regions']) > 5:\n",
    "        print(f\"  ... and {len(comparison['conservation_regions']) - 5} more regions\")\n",
    "else:\n",
    "    print(\"No highly conserved regions found (>90% identity)\")\n",
    "\n",
    "print(\"\\n💡 BIOLOGICAL INTERPRETATION\")\n",
    "print(\"-\" * 50)\n",
    "if 'similarity' in comparison:\n",
    "    identity = comparison['similarity']['percent_identity']\n",
    "    \n",
    "    if identity > 90:\n",
    "        print(\"• Extremely high conservation suggests critical functional importance\")\n",
    "        print(\"• ATR gene is likely essential for cellular function\")\n",
    "        print(\"• Mutations in conserved regions may be deleterious\")\n",
    "    elif identity > 70:\n",
    "        print(\"• Good conservation typical of important genes\")\n",
    "        print(\"• Some variation allowed while maintaining function\")\n",
    "        print(\"• Species-specific adaptations may be present\")\n",
    "    \n",
    "    if comparison['conservation_regions']:\n",
    "        total_conserved = sum(r['end'] - r['start'] for r in comparison['conservation_regions'])\n",
    "        percent_conserved = (total_conserved / comparison['similarity']['overlap_length']) * 100\n",
    "        print(f\"• {percent_conserved:.1f}% of sequence is highly conserved (>90%)\")\n",
    "        print(\"• These regions likely contain critical functional domains\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Your Turn: Practice Challenges\n",
    "\n",
    "Now it's time to apply what you've learned! Try these challenges of increasing difficulty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: CpG Island Finder (Intermediate)\n",
    "\n",
    "CpG islands are regions with high frequency of CG dinucleotides. They're important regulatory regions.\n",
    "\n",
    "**Task:** Write a function to find CpG islands (regions with >60% GC content and high CG frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cpg_islands(sequence, window_size=200, gc_threshold=60, cg_threshold=5):\n",
    "    \"\"\"\n",
    "    Find potential CpG islands in a sequence\n",
    "    \n",
    "    Parameters:\n",
    "    - sequence: DNA sequence to analyze\n",
    "    - window_size: size of window to check\n",
    "    - gc_threshold: minimum GC% for CpG island\n",
    "    - cg_threshold: minimum CG dinucleotide percentage\n",
    "    \n",
    "    Returns:\n",
    "    - List of dictionaries with CpG island information\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement CpG island finding\n",
    "    # Hints:\n",
    "    # 1. Use sliding window approach\n",
    "    # 2. Calculate GC content for each window\n",
    "    # 3. Count CG dinucleotides (sequence.count('CG'))\n",
    "    # 4. Store regions that meet both thresholds\n",
    "    \n",
    "    cpg_islands = []\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    return cpg_islands\n",
    "\n",
    "# Test with human ATR\n",
    "# islands = find_cpg_islands(human_atr[:5000])\n",
    "# print(f\"Found {len(islands)} potential CpG islands\")\n",
    "# for island in islands:\n",
    "#     print(island)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Open Reading Frame (ORF) Finder (Advanced)\n",
    "\n",
    "Find all potential protein-coding regions in a sequence.\n",
    "\n",
    "**Task:** Write a function to find ORFs (start with ATG, end with stop codon, minimum length 300bp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_orfs(sequence, min_length=300):\n",
    "    \"\"\"\n",
    "    Find all Open Reading Frames in a sequence\n",
    "    \n",
    "    ORF definition:\n",
    "    - Starts with ATG (start codon)\n",
    "    - Ends with TAA, TAG, or TGA (stop codons)\n",
    "    - Minimum length requirement\n",
    "    - In-frame (divisible by 3)\n",
    "    \n",
    "    Returns:\n",
    "    - List of ORFs with position and sequence information\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement ORF finding\n",
    "    # Hints:\n",
    "    # 1. Search for all ATG positions\n",
    "    # 2. For each ATG, look for stop codons in the same frame\n",
    "    # 3. Calculate ORF length\n",
    "    # 4. Check minimum length requirement\n",
    "    # 5. Consider all three reading frames\n",
    "    \n",
    "    orfs = []\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    return orfs\n",
    "\n",
    "# Test\n",
    "# orfs = find_orfs(human_atr[:10000], min_length=300)\n",
    "# print(f\"Found {len(orfs)} ORFs\")\n",
    "# for i, orf in enumerate(orfs[:3], 1):  # Show first 3\n",
    "#     print(f\"ORF {i}: {orf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Mutation Analyzer (Advanced)\n",
    "\n",
    "Compare sequences and identify mutations.\n",
    "\n",
    "**Task:** Write a function to find all differences between two sequences and classify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mutations(seq1, seq2, seq1_name=\"Reference\", seq2_name=\"Query\"):\n",
    "    \"\"\"\n",
    "    Find and classify mutations between two sequences\n",
    "    \n",
    "    Mutation types:\n",
    "    - SNP: Single nucleotide polymorphism (one base different)\n",
    "    - Transition: A↔G or C↔T (purine↔purine or pyrimidine↔pyrimidine)\n",
    "    - Transversion: Other SNPs\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with mutation statistics and positions\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement mutation analysis\n",
    "    # Hints:\n",
    "    # 1. Compare sequences position by position\n",
    "    # 2. Classify each difference\n",
    "    # 3. Count transition vs transversion\n",
    "    # 4. Calculate mutation rate\n",
    "    \n",
    "    mutations = {\n",
    "        'snps': [],\n",
    "        'transitions': 0,\n",
    "        'transversions': 0,\n",
    "        'total_mutations': 0,\n",
    "        'mutation_rate': 0\n",
    "    }\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    return mutations\n",
    "\n",
    "# Test\n",
    "# mutations = analyze_mutations(human_atr[:1000], mouse_atr[:1000], \"Human\", \"Mouse\")\n",
    "# print(f\"Total mutations: {mutations['total_mutations']}\")\n",
    "# print(f\"Mutation rate: {mutations['mutation_rate']:.2f}%\")\n",
    "# print(f\"Transitions: {mutations['transitions']}\")\n",
    "# print(f\"Transversions: {mutations['transversions']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4: Custom Analysis Pipeline (Expert)\n",
    "\n",
    "Create your own comprehensive sequence analysis pipeline!\n",
    "\n",
    "**Task:** Combine multiple analyses into a single pipeline function that:\n",
    "1. Performs quality control\n",
    "2. Calculates statistics\n",
    "3. Finds restriction sites\n",
    "4. Identifies ORFs\n",
    "5. Generates a summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_sequence_analysis(sequence, sequence_name=\"Unknown\"):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis pipeline for DNA sequences\n",
    "    \n",
    "    Performs:\n",
    "    - Quality control\n",
    "    - Basic statistics\n",
    "    - Composition analysis  \n",
    "    - Restriction site mapping\n",
    "    - ORF identification\n",
    "    - Summary report generation\n",
    "    \n",
    "    Returns:\n",
    "    - Complete analysis report dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Build your pipeline!\n",
    "    # Use the tools from above or create your own\n",
    "    \n",
    "    report = {\n",
    "        'sequence_name': sequence_name,\n",
    "        'qc_results': {},\n",
    "        'statistics': {},\n",
    "        'restriction_sites': {},\n",
    "        'orfs': [],\n",
    "        'summary': \"\"\n",
    "    }\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Test your pipeline\n",
    "# report = comprehensive_sequence_analysis(human_atr[:10000], \"Human ATR Sample\")\n",
    "# print(report['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "You've built a complete **DNA Analysis Toolkit** using Lecture 2 concepts!\n",
    "\n",
    "### 💡 What You've Accomplished:\n",
    "\n",
    "1. ✅ **Basic Statistics** - Analyze sequence composition and properties\n",
    "2. ✅ **Nucleotide Analysis** - Use dictionaries to organize composition data\n",
    "3. ✅ **Codon Classification** - Apply conditionals and dictionaries for genetic code\n",
    "4. ✅ **Restriction Mapping** - Find enzyme cut sites with string searching\n",
    "5. ✅ **Quality Control** - Implement comprehensive validation logic\n",
    "6. ✅ **Species Comparison** - Combine all skills for advanced analysis\n",
    "\n",
    "### 🔑 Skills Mastered:\n",
    "\n",
    "**String Manipulation:**\n",
    "- `.upper()`, `.lower()`, `.strip()` for cleaning\n",
    "- `.count()`, `.find()` for searching\n",
    "- Slicing `[start:end]` for subsequences\n",
    "\n",
    "**Conditionals:**\n",
    "- `if/elif/else` for decision making\n",
    "- Comparison operators for validation\n",
    "- Logical operators (`and`, `or`, `not`)\n",
    "\n",
    "**Dictionaries:**\n",
    "- Storing biological data (codons, enzymes)\n",
    "- Organizing analysis results\n",
    "- Lookups and mappings\n",
    "\n",
    "### 🚀 Real-World Applications:\n",
    "\n",
    "These tools form the foundation for:\n",
    "- **Genome analysis** - Finding genes and regulatory elements\n",
    "- **Primer design** - Calculating Tm and checking specificity\n",
    "- **Cloning strategies** - Restriction enzyme selection\n",
    "- **Comparative genomics** - Species and variant analysis\n",
    "- **Quality control** - Validating sequencing data\n",
    "\n",
    "### 📚 Next Steps:\n",
    "\n",
    "In future lectures, you'll learn:\n",
    "- **Loops** for processing multiple sequences efficiently\n",
    "- **File I/O** for reading real FASTA/FASTQ files\n",
    "- **Functions** for organizing reusable code\n",
    "- **Libraries** like BioPython for advanced analysis\n",
    "- **Visualization** for presenting results\n",
    "\n",
    "**Keep this notebook!** You'll use these patterns throughout your bioinformatics journey.\n",
    "\n",
    "**Happy analyzing!** 🧬💻🔬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
