{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCzXS_48GTgf"
   },
   "source": [
    "# Downloading and Caching Large Datasets\n",
    "\n",
    "## Why We Need This Notebook\n",
    "\n",
    "In this course, we work with two large CSV files from the DepMap project:\n",
    "- **CRISPR dependency data** (~350 MB): Gene essentiality scores across cancer cell lines\n",
    "- **Gene expression data** (~450 MB): RNA expression levels for thousands of genes\n",
    "\n",
    "### The Problem\n",
    "These files are too large to download repeatedly every time you open a Colab notebook. Each time you restart your Colab session, the runtime's temporary storage is wiped clean.\n",
    "\n",
    "### The Solution\n",
    "We'll download these files **once** from Zenodo (a research data repository) and save them to your **Google Drive**. Your Google Drive is persistent storage that stays accessible across all your Colab sessions.\n",
    "\n",
    "### Benefits\n",
    "- **Faster**: Load from Google Drive in seconds instead of downloading each time\n",
    "- **Reliable**: No need to depend on external servers every session\n",
    "- **Efficient**: Save bandwidth and time\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. **Run this notebook ONCE** to download and cache the data\n",
    "2. **In future notebooks**, simply mount Google Drive and load the cached files\n",
    "3. The data will be saved in: `My Drive/Colab_Data/`\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXuZUUbtGTgi"
   },
   "source": [
    "## Step 1: Mount Google Drive\n",
    "\n",
    "This allows Colab to access your Google Drive storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtIt2OYQGTgi"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "\n",
    "# Create a directory for our data if it doesn't exist\n",
    "data_dir = pathlib.Path('data')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"‚úì Data directory ready: {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MG5hij2VGTgj"
   },
   "source": [
    "## Step 2: Download CRISPR Dependency Data\n",
    "\n",
    "This file contains gene essentiality scores - which genes are critical for cancer cell survival.\n",
    "\n",
    "**Note**: This may take 2-3 minutes depending on your internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhcyfHlLGTgj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Zenodo URL for CRISPR dependency data\n",
    "dependency_url = 'https://zenodo.org/records/17609722/files/dependency_df_nan.csv?download=1'\n",
    "\n",
    "print(\"Downloading CRISPR dependency data from Zenodo...\")\n",
    "print(\"This may take a few minutes for the large file (~350 MB)...\\n\")\n",
    "\n",
    "\n",
    "# Read the CSV directly from URL\n",
    "dependency_df = pd.read_csv(dependency_url)\n",
    "\n",
    "# Save to Google Drive with our chosen filename\n",
    "dependency_path = pathlib.Path(data_dir / 'dependency.csv')\n",
    "dependency_df.to_csv(dependency_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(\"‚úì Download complete!\")\n",
    "print(f\"‚úì Saved as: {dependency_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT3hOvQcGTgj"
   },
   "source": [
    "## Step 3: Download Gene Expression Data\n",
    "\n",
    "This file contains RNA expression levels for thousands of genes across cancer cell lines.\n",
    "\n",
    "**Note**: This may also take 2-3 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QTp_gnRGTgj"
   },
   "outputs": [],
   "source": [
    "# Zenodo URL for gene expression data\n",
    "expression_url = 'https://zenodo.org/records/17609575/files/expression_df_nan.csv?download=1'\n",
    "\n",
    "print(\"Downloading gene expression data from Zenodo...\")\n",
    "print(\"This may take a few minutes for the large file (~450 MB)...\\n\")\n",
    "\n",
    "\n",
    "# Read the CSV directly from URL\n",
    "expression_df = pd.read_csv(expression_url)\n",
    "\n",
    "# Save to Google Drive with our chosen filename\n",
    "expression_path = pathlib.Path(data_dir / 'expression.csv')\n",
    "expression_df.to_csv(expression_path, index=False)\n",
    "\n",
    "\n",
    "print(\"‚úì Download complete!\")\n",
    "print(f\"‚úì Saved as: {expression_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLR37QKfGTgj"
   },
   "source": [
    "## Step 4: Verify the Cached Files\n",
    "\n",
    "Let's test loading the files from Google Drive to make sure everything worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0sjKZgsGTgj"
   },
   "outputs": [],
   "source": [
    "print(\"Testing: Loading cached files from Google Drive...\\n\")\n",
    "\n",
    "# Test loading dependency data\n",
    "print(\"Loading dependency.csv...\")\n",
    "\n",
    "test_dependency = pd.read_csv(pathlib.Path(data_dir / 'dependency.csv'))\n",
    "\n",
    "print(\"‚úì Loaded data successfully\")\n",
    "print(f\"  Shape: {test_dependency.shape}\\n\")\n",
    "\n",
    "# Test loading expression data\n",
    "print(\"Loading expression.csv...\")\n",
    "\n",
    "test_expression = pd.read_csv(pathlib.Path(data_dir / 'expression.csv'))\n",
    "\n",
    "print(\"‚úì Loaded data successfully\")\n",
    "print(f\"  Shape: {test_expression.shape}\\n\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SUCCESS! Both files are cached and ready to use.\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nYour files are stored at:\")\n",
    "print(\"  üìÅ {data_dir}\")\n",
    "print(\"     ‚îú‚îÄ‚îÄ dependency.csv\")\n",
    "print(\"     ‚îî‚îÄ‚îÄ expression.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wi6UWMzJGTgk"
   },
   "source": [
    "---\n",
    "\n",
    "## How to Use These Files in Other Notebooks\n",
    "\n",
    "Now that you've cached the data, here's how to load it in your assignment notebooks:\n",
    "\n",
    "```python\n",
    "# 1. Pathlib Library import\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# 2. Load the cached files\n",
    "data_dir = pathlib.Path('data')\n",
    "\n",
    "dependency_df = pd.read_csv(f'{data_dir}/dependency.csv')\n",
    "expression_df = pd.read_csv(f'{data_dir}/expression.csv')\n",
    "\n",
    "# 3. Start analyzing!\n",
    "print(f\"Dependency data: {dependency_df.shape}\")\n",
    "print(f\"Expression data: {expression_df.shape}\")\n",
    "```\n",
    "\n",
    "### Tips\n",
    "- Loading locally takes ~10-20 seconds (much faster than downloading!)\n",
    "- You only need to run this download notebook once\n",
    "- If the data gets updated, just re-run this notebook to refresh your cache\n",
    "- Make sure to mount Google Drive in every new Colab session\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "\n",
    "**Problem**: Download is very slow\n",
    "- **Solution**: This is normal for large files. Be patient - you only do this once!\n",
    "\n",
    "**Problem**: \"Memory error\" when loading\n",
    "- **Solution**: Go to Runtime ‚Üí Change runtime type ‚Üí Select \"High-RAM\" option\n",
    "\n",
    "---\n",
    "\n",
    "**You're all set!** üéâ\n",
    "\n",
    "Your data is now safely stored locally and ready for your assignments."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
